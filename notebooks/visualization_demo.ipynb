{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sharks from Space - Enhanced Visualization Demo\n",
        "\n",
        "This notebook demonstrates the enhanced visualization capabilities of the Sharks from Space project, including:\n",
        "\n",
        "- Time series visualization of habitat predictions\n",
        "- Multi-model comparison\n",
        "- Interactive map generation\n",
        "- Statistical analysis of predictions\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have run the enhanced pipeline:\n",
        "```bash\n",
        "make all-enhanced  # For full pipeline with enhanced visualization\n",
        "# or\n",
        "make demo-enhanced  # For demo with time series\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "from PIL import Image\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../src')\n",
        "from utils import load_config, setup_logging\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load configuration\n",
        "config = load_config('../config/params.yaml')\n",
        "logger = setup_logging()\n",
        "\n",
        "print(\"Enhanced Visualization Demo - Sharks from Space\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Discover Available Prediction Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discover_prediction_files(data_dir='../web/data'):\n",
        "    \"\"\"Discover available prediction files and organize by model and date.\"\"\"\n",
        "    files = {\n",
        "        'xgboost': [],\n",
        "        'random_forest': [],\n",
        "        'lightgbm': []\n",
        "    }\n",
        "    \n",
        "    # Look for PNG files\n",
        "    png_pattern = os.path.join(data_dir, 'habitat_prob_*.png')\n",
        "    for file_path in glob.glob(png_pattern):\n",
        "        filename = os.path.basename(file_path)\n",
        "        # Parse filename: habitat_prob_{model}_{date}.png\n",
        "        parts = filename.replace('habitat_prob_', '').replace('.png', '').split('_')\n",
        "        if len(parts) >= 2:\n",
        "            model = parts[0]\n",
        "            date_str = parts[1]\n",
        "            if model in files:\n",
        "                files[model].append((date_str, file_path))\n",
        "    \n",
        "    # Sort by date\n",
        "    for model in files:\n",
        "        files[model].sort(key=lambda x: x[0])\n",
        "    \n",
        "    return files\n",
        "\n",
        "# Discover files\n",
        "prediction_files = discover_prediction_files()\n",
        "available_models = [model for model, file_list in prediction_files.items() if file_list]\n",
        "\n",
        "print(f\"Available models: {available_models}\")\n",
        "for model in available_models:\n",
        "    print(f\"{model}: {len(prediction_files[model])} prediction files\")\n",
        "    if prediction_files[model]:\n",
        "        dates = [item[0] for item in prediction_files[model]]\n",
        "        print(f\"  Date range: {dates[0]} to {dates[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Analyze Prediction Metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata if available\n",
        "metadata_path = '../web/data/prediction_metadata.json'\n",
        "if os.path.exists(metadata_path):\n",
        "    with open(metadata_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "    print(\"Prediction Metadata:\")\n",
        "    print(json.dumps(metadata, indent=2))\n",
        "else:\n",
        "    print(\"No metadata file found\")\n",
        "    metadata = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualize Time Series of Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_time_series_plot(files, model='xgboost'):\n",
        "    \"\"\"Create a time series plot of prediction files.\"\"\"\n",
        "    if model not in files or not files[model]:\n",
        "        print(f\"No files found for model: {model}\")\n",
        "        return\n",
        "    \n",
        "    dates = [item[0] for item in files[model]]\n",
        "    file_paths = [item[1] for item in files[model]]\n",
        "    \n",
        "    # Convert dates to datetime\n",
        "    date_objects = [datetime.strptime(date_str, '%Y%m%d') for date_str in dates]\n",
        "    \n",
        "    # Create subplot for time series\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(f'Habitat Prediction Time Series - {model.title()}', fontsize=16)\n",
        "    \n",
        "    # Plot 1: Sample images over time\n",
        "    sample_indices = np.linspace(0, len(file_paths)-1, 4, dtype=int)\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        ax = axes[i//2, i%2]\n",
        "        img = Image.open(file_paths[idx])\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f'{dates[idx]}')\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create time series visualization for first available model\n",
        "if available_models:\n",
        "    create_time_series_plot(prediction_files, available_models[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Multi-Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_models(files):\n",
        "    \"\"\"Compare predictions across different models.\"\"\"\n",
        "    if len(available_models) < 2:\n",
        "        print(\"Need at least 2 models for comparison\")\n",
        "        return\n",
        "    \n",
        "    # Find common dates across models\n",
        "    all_dates = set()\n",
        "    for model in available_models:\n",
        "        dates = set(item[0] for item in files[model])\n",
        "        all_dates.update(dates)\n",
        "    \n",
        "    common_dates = sorted(list(all_dates))\n",
        "    print(f\"Found {len(common_dates)} unique dates across all models\")\n",
        "    \n",
        "    # Create comparison plot\n",
        "    fig, axes = plt.subplots(len(available_models), 1, figsize=(12, 4*len(available_models)))\n",
        "    if len(available_models) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    fig.suptitle('Multi-Model Comparison', fontsize=16)\n",
        "    \n",
        "    for i, model in enumerate(available_models):\n",
        "        ax = axes[i]\n",
        "        model_dates = [item[0] for item in files[model]]\n",
        "        model_files = [item[1] for item in files[model]]\n",
        "        \n",
        "        # Plot available dates for this model\n",
        "        date_objects = [datetime.strptime(date_str, '%Y%m%d') for date_str in model_dates]\n",
        "        ax.scatter(date_objects, [1]*len(date_objects), label=f'{model} predictions', alpha=0.7)\n",
        "        ax.set_title(f'{model.title()} Model - Available Predictions')\n",
        "        ax.set_ylabel('Model')\n",
        "        ax.set_xlabel('Date')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Compare models\n",
        "compare_models(prediction_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Interactive Map Generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
